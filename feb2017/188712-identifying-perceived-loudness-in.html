<head>
    <link rel="icon" href="../Assets/Logo/CJUR.svg">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js">
    </script>
    <link rel="stylesheet" href="../article.css">
</head>

<body>
    <header>
        <a href="index.html">
            <img src="../Assets/Logo/CJUR-white.svg" class="logo">
            <img src="../Assets/Logo/cjur-titling-white.svg" class="logo">
        </a>
    </header>
    <div class="navbar">
        <div class="nav-button" id="browse">Browse
            <div class="panel" id="panel-A">
                <a href="../research.html">
                    <div class="destination">
                        <img src="Assets/Capitals/FloralA.svg"><br />
                        <span class="destination-name">Research</span><br />
                        <span class="destination-desc">Primary observations made by undergraduates of various disciplines and fields</span>
                    </div>
                </a>
                <div class="panel-divider"></div>
                <a href="../reviews.html">
                    <div class="destination">
                        <img src="Assets/Capitals/FloralR.svg"><br />
                        <span class="destination-name">Review</span><br />
                        <span class="destination-desc">Peer-reviewed literature, systematic, and scoping reviews on a variety of subjects</span>
                    </div>
                </a>
                <div class="panel-divider"></div>
                <a href="../communications.html">
                    <div class="destination">
                        <img src="Assets/Capitals/FloralC.svg"><br />
                        <span class="destination-name">Communications</span><br />
                        <span class="destination-desc">Undergraduates raise awareness of lesser-known scientific passions</span>
                    </div>
                </a>
            </div>
        </div>
        <div class="nav-button" id="button-B">Journal
            <div class="panel" id="panel-B">
                <div class="destination">
                    <span class="destination-name">Current issue: <em>Vol 5 No. 1</em></span><br />
                    <span class="destination-desc">Bangladesh and the 4th MDG</span>
                </div>
                <a href="../journal.html" id="latest-issue-panel">
                    <div class="destination">
                        <img src="Assets/Covers/V5-No1.png"><br />
                        <span class="destination-desc">Aug 2020</span>
                    </div>
                </a>
                <div class="panel-divider"></div>
                <a href="../journal.html" id="past-1">
                    <div class="destination">
                        <img src="Assets/Covers/V4-No1.png"><br />
                        <span class="destination-desc">Dec 2019</span>
                    </div>
                </a>
                <a href="../journal.html" id="past-2">
                    <div class="destination">
                        <img src="Assets/Covers/V3-No1.jpg"><br />
                        <span class="destination-desc">Aug 2018</span>
                    </div>
                </a>
            </div>
        </div>
        <div class="nav-button" id="button-C">About
            <div class="panel" id="panel-c">
                <a href="../authors.html">
                    <div class="destination">
                        <img src="Assets/Thumbs/undergrad.jpg"><br />
                        <span class="destination-name">Getting involved</span><br />
                        <span class="destination-desc">Share your work with a national audience and gain experience with the peer review process</span>
                    </div>
                </a>
                <a href="../editors.html">
                    <div class="destination">
                        <img src="Assets/Thumbs/grad2.png"><br />
                        <span class="destination-name">The journal</span><br />
                        <span class="destination-desc">CJUR provides an accessible platform for undergraduates from all universities across Canada</span>
                    </div>
                </a>
            </div>
        </div>
    </div>
		<div class="top">
			<span>CJUR (2017) &blacktriangleright; Research</span>
			<h1>Identifying perceived loudness in audio signals</h1>
			<h3>Bill S Lin<sup>1</sup> & Wesley Fisher<sup>1</sup></h3>
		</div>

	<div class="wrapper">
		<div class="sidebar">
			<div class="tabs">
				<span class="tab active-tab" id="info-tab" rel="info">Information</span>
				<span class="tab" id="contents-tab" rel="contents">Contents</span>
			</div>
			<!-- <div class="side-panel"> -->
				<div class="side-menu active-panel" id="info">
					<span class="menu-item"><sup>1</sup>University of Waterloo, Waterloo, ON</span>
					<span class="menu-item">Accepted 26 December 2016</span>
					<span class="menu-item">Published February 2017</span>
					<span class="menu-item">Copyright: © The Authors. This open-access article is licensed under a Creative Commons Attribution 4.0 International Licence.</span>
					<a href="https://cjur.ca/wp-content/uploads/2017/03/Identifying-Perceived-Loudness-in-Audio-Signals.pdf">Download PDF</a>
				</div>
				<div class="side-menu" id="contents">
					<span class="menu-item">Background</span>
					<span class="menu-item">Linking angiogenesis and brain neurogenesis/gliogenesis</span>
					<span class="menu-item">Assessing the therapeutic potential of Prmt1 targeting in vitro</span>
					<span class="menu-item">Prmt1 and its effects on neurogenesis/gliogenesis in a murine model of Vascular Dementia</span>
					<span class="menu-item">References</span>
				</div>
			<!-- </div> -->
		</div>
		<div class="article">
			<h2>Abstract</h2>
	
			<p>In processing audio, it can be helpful to have algorithms that can extract volume and loudness information.
				One application of this would be finding speech in long intervals of silence. Digital audio files, which
				contain raw information, may not represent how a human can perceive the sound. For example, high and low
				frequencies of sound with equal intensities will be perceived as having different levels of loudness. This
				paper presents a series of processing operations to be performed on sound signals, which attempt to find the
				loudness of sounds as perceived by a human. Previously used methods of calculating perceived loudness
				includes looking at the frequency spectrum of sounds <sup>[1]</sup>. The first operation accounts for the
				human perception of loudness at different frequencies. The second creates an envelope of the sound signal,
				while preventing impulses from getting filtered out. These impulses are short bursts of sound such as a
				gunshot or a hand clap. The third operation accounts for the human perception of impulse loudness. The
				output of this process is an envelope of the original sound signal, which represents how a human would
				perceive the audio volume. This removes the sinusoidal components in the sound signal and maintains the
				sound amplitude information, with some other minor adjustments.</p>
			<h2>Introduction</h2>
	
			<p>
				In large sound audio file, it can sometimes be desirable to have a computer quickly identify the louder
				sections of an audio clip for further processing. For example, algorithms that do speech processing need to
				identify the periods of silence in an audio, which are of no interest to the algorithm. Similarly,
				algorithms processing audio recordings of birds chirping may want to identify where in the audio file the
				chirping actually occurs.
			</p>
			<p>
				A simple naive approach to solve this problem could be to set a threshold on the audio amplitude. This way,
				any signal with amplitude less than the threshold could be deemed as “silence” and any signal with amplitude
				greater than the threshold could be deemed as “sound”. The problem with this technique is that it does not
				consider how humans perceive sound. For example, the human ear is much less sensitive to very high frequency
				sound <sup>[2]</sup>. Similarly, short sound impulses are also perceived as quieter by humans
				<sup>[2]</sup>. On top of this, because sound waves oscillate up and down (like a sine wave), it becomes
				more difficult to identify the actual peak amplitude of a given sound signal.
			</p>
			<p>
				This paper presents a signal processing method that attempts to extract the perceived loudness information
				from an audio signal. This is done by taking the envelope of the audio signal. On top of this, adjustments
				based on audio frequency and short impulses are made. The resulting signal makes it easy to programmatically
				identify the loudness of an audio file at any point in time.
			</p>
			<h2>Methodology</h2>
	
			<p>
				To extract the perceived loudness from an audio signal, three steps are performed. Firstly, the frequency
				components of the signal are modified to reflect what is being perceived by humans. For example, frequencies
				to which humans are less sensitive are attenuated, and frequencies to which humans are more sensitive are
				amplified, by amounts described by equal-loudness curves and transfer functions used by Rimell et al.
				<sup>[3]</sup>. Secondly, the envelope of the audio signal is found to eliminate the actual sound vibrations
				and preserve the amplitude information of the vibrations. Finally, short sound impulses in the audio signal
				are identified. These impulses are then attenuated based on their duration, according to a human’s ability
				to perceive these impulses as described by Everest <sup>[2]</sup>. The following subsections discuss the
				detailed steps used for each operation.
			</p>
			<h3>Frequency adjustment</h3>
			<p>
				Given equal sound pressures, different frequencies are perceived with different levels of loudness by
				humans. In particular, low and high frequencies are attenuated by human perception <sup>[2]</sup>. A study
				of this phenomenon lead to the creation of a standard set of equal-loudness curves, as discussed in the
				referenced work <sup>[4]</sup>. These curves represent the sound pressures required across all frequencies
				to create sounds with the same perceived loudness.
			</p>
			<p>
				One of the works in the references identified a transfer function which approximates the filtering effect of
				the human ear and human perception <sup>[3]</sup>. This filtering effect corresponds to an equal-loudness
				curve. The transfer function from the referenced work is applied in this paper in order to perform
				A-weighting on audio signals which attenuates the high and low sound frequencies
			</p>
			<h3>Signal envelope</h3>
			<p>
				To identify the amplitude of an audio signal, the envelope of the sound signal needs to be identified. The
				envelope signal traces the maximum peaks of the original signal and removes the oscillatory components.
				Although there already exist methods to do this, such as the Hilbert Transform Filter <sup>[5]</sup>, a
				technique is presented here that also preserves the duration of impulses in audio. Doing so allows further
				processing to be done to attenuate the amplitude of the impulses to better reflect how they are perceived by
				the human ear.
			</p>
			<p>
				To obtain the amplitude envelope of the audio signal, the absolute values of the signal is first obtained.
				After this, a double sliding window is applied to each sample in the input signal. As shown in Figure 1, the
				sample on which the double window is being applied is shared by each of the half windows. For each half
				window, the maximum value is found. Finally, the output sample value is the minimum value of the two half
				window maxima. In the case of the example, the maximum in the first half window is 9, while the maximum in
				the second half window is 10. This means that the output sample value is 9.
			</p>
			<p>
				The double sliding window eliminates higher frequency vibrations by replacing oscillation values with nearby
				peak values. Figure 2 shows an example of this, where the input signal dips down because of a higher
				frequency vibration but is replaced with a neighboring maximum value, A, in the output.
			</p>
			<p>
				This signal filter is able to preserve the width of impulses because this filter will only output a high
				value when samples from both sub-windows are high. For an impulse, this would only happen with the sliding
				window is directly centered underneath the impulse. Figure 3 provides an example of this.
			</p>
			<p>
				The size of the double sliding window determines the frequencies that will be eliminated in order to obtain
				the envelope function. Since humans are only able to hear sounds with frequency above 20Hz <sup>[2]</sup>,
				the window is selected such that it covers exactly one period of a 20Hz sine wave. This eliminates all human
				hearable oscillations and only preserves the envelope of the signal.
			</p>
			<figure class="figure">
				<img src="perceived_loudness_fig1.png">
				<figcaption>Fig. 1: double sliding window</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig2.png">
				<figcaption>Fig. 2: double sliding window removing high frequency</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig3.png">
				<figcaption>Fig. 3: Impulse double sliding window</figcaption>
			</figure>
	
			<h3>Impulse correction</h3>
			<p>
				The human ear is not as sensitive to short impulse sounds as other sounds. The technique in this subsection
				provides a way to modify the signal so that short impulses are attenuated to match how they would be
				perceived. According to a figure in The Master Handbook of Acoustics, a 10ms impulse needs to be roughly
				10dB higher than a 200ms impulse for humans to perceive them as the same loudness. Moreover, the
				relationship between impulse duration (in milliseconds) and perceived loudness (in decibels) is roughly
				linear with respect to the logarithm of the impulse duration up until 200ms <sup>[2]</sup>. Using this
				information, a simple linear equation can be found that relates the duration of an impulse to the sound
				pressure increase to maintain equal loudness. This relation is shown in Equation 1.
			</p>
			<p>
				In order to test this algorithm, three very different sound clips from the SYDE252 course at the University
				of Waterloo <sup>[6]</sup> are used. The first one is a drum sound clip containing many impulses. The second
				sound clip is that of a robin chirping, which contains high frequency sounds. Lastly, there is a sound clip
				of a person saying a sentence. The sound signals can be found in Figure 6, Figure 7, and Figure 8
				respectively.
			</p>
			<figure class="equation">
				<img src="perceived_loudness_eq1.png">
				<figcaption>Eq. 1: sound pressure to maintain equal loudness</figcaption>
			</figure>
			<p>
				P<sub>increase</sub> is the increase in sound pressure required to maintain equal perceived loudness in
				decibels and t is the duration of the impulse in milliseconds. The equation is valid for impulse durations
				less than 200ms. Equation 2 shows the conversion between decibels and magnitude.
			</p>
			<figure class="equation">
				<img src="perceived_loudness_eq2.png">
				<figcaption>Eq. 2: pressure increase conversion from dB to grain ratio</figcaption>
			</figure>
			<p>
				In order to modify the signal, the impulses need to first be identified. Afterwards, for each impulse, the
				amplitude is scaled down by dividing the original impulse amplitude by P<sub>increase_Mag</sub>.
			</p>
			<p>
				In order to identify the impulses in the signal, all of the peaks are identified in the signal. A peak in
				this context is where a sample is greater in value than both of its adjacent samples. Afterwards, for each
				peak, the area under the surrounding 200ms is compared to that of an ideal (rectangular) impulse. The ideal
				impulse rectangle is then gradually shrunk in duration until the area under the signal is close to that of
				the rectangular impulse. When the area of the signal is within a certain threshold to that of an ideal
				impulse, the impulse in the signal is then shrunk based on the ratio in Equation 2.
			</p>
			<p>
				Figure 4 shows an example of this impulse correction. The blue rectangle is the starting 200ms area around
				the peak. The width of this rectangle is gradually reduced until it reaches the size of the red rectangle.
				At this point, the area within both the red rectangle and the signal envelope, is greater than a certain
				proportion of the red rectangle’s area. Experimentally, a threshold of 0.4 times the ideal rectangular
				impulse (red rectangle) area is effective at identifying most of the short sound spikes in the signal.
				Finally, the part of the signal overlapped by the red rectangle is then scaled using the factor calculated
				in Equation 2. Equation 3 shows the formula used to calculate the corrected signal value. The corresponding
				values used in the equation, found in the original signal, can be found in Figure 5.
			</p>
			<figure class="equation">
				<img src="perceived_loudness_eq3.png">
				<figcaption>Eq. 3: impulse correction formula</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig4.png">
				<figcaption>Fig. 4: impulse correction</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig5.png">
				<figcaption>Fig. 5: impulse correction variables</figcaption>
			</figure>
	
			<h3>Testing the methodology</h3>
			<p>
				In order to test this algorithm, three very different sound clips from the SYDE252 course at the University
				of Waterloo <sup>[6]</sup> are used. The first one is a drum sound clip containing many impulses. The second
				sound clip is that of a robin chirping, which contains high frequency sounds. Lastly, there is a sound clip
				of a person saying a sentence. The sound signals can be found in Figure 6, Figure 7, and Figure 8
				respectively.
			</p>
			<figure class="figure">
				<img src="perceived_loudness_fig6.png">
				<figcaption>Fig. 6: drum loop audio signal</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig7.png">
				<figcaption>Fig. 7: robin chirp audio signal</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig8.png">
				<figcaption>Fig. 8: person speaking audio signal</figcaption>
			</figure>
	
			<h2>Results and discussion</h2>
	
			<p>
				The three filtering techniques described in the previous section were applied successively to each signal.
			</p>
			<p>
				For the drum loop audio signal, Figure 9 shows the frequency adjusted audio signal overlaid on top of the
				original drum loop signal. As shown, the higher frequency vibrations, which are less audible to the human
				ear are attenuated to better reflect the human’s perception of sound.
			</p>
			<p>
				In Figure 10, the blue signal shows the envelope of the signal in Figure 9. As shown, in the image, the
				double sliding window was able to effectively remove all of the higher frequency oscillations and output a
				signal that roughly represented the amplitude of the input. Finally, the orange signal in Figure 10 shows
				the output after the impulses have been shrunk accordingly. From the figure, it is possible to see that all
				of the short sound spikes have been scaled down.
			</p>
			<p>
				A similar procedure has been done to the other sound clips. The resulting audio amplitude signals are shown
				in Figure 11 and Figure 12. From these two figures, the amplitude of the audio signal at any given point can
				be easily estimated.
			</p>
			<p>
				Once the amplitude of the sound file at any given point can be found, a computer algorithm can easily read
				off an estimate of how loud a sound signal is just by finding the signal's value at a particular point.
				Moreover, if it is desired to see whether sound amplitude reaches above a certain threshold, a simple
				thresholding algorithm can be applied to the processed signals.
			</p>
			<figure class="figure">
				<img src="perceived_loudness_fig9.png">
				<figcaption>Fig. 3: drum loop frequency adjusted</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig10.png">
				<figcaption>Fig. 3: drum loop output signal</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig11.png">
				<figcaption>Fig. 3: robin chirp output signal</figcaption>
			</figure>
			<figure class="figure">
				<img src="perceived_loudness_fig12.png">
				<figcaption>Fig. 3: person speaking output signal</figcaption>
			</figure>
	
			<h2>Conclusion and future work</h2>
	
			<p>
				In conclusion, this paper presents a combination of techniques that can output the amplitude information of
				an audio signal. On top of this, certain adjustments are made so that the amplitude values better reflect
				what would be perceived by a human being. The method presented can be used so that a computer can
				algorithmically identify portions of an audio signal that humans would perceive as louder or quieter.
			</p>
			<p>
				Although the method presented here does seem to work well for the three audio signals used in the
				experiment, more rigorous testing of this method should be done in the future
			</p>
	
			<h2>References</h2>
	
			<ol class="refs">
				<li>G. Seshadri and B. Yegnanarayana, “Perceived loudness of speech based on the characteristics of glottal
					excitation source,” Journal of the Acoustic Society of America, vol. 126, no. 4, pp. 2061-2071, 2009.
				</li>
				<li>F. A. Everest, The Master Handbook of Acoustics, New York: McGraw-Hill, 2001.</li>
				<li>A. N. Rimell, N. J. Mansfield and G. S. PAddan, “Design of digital filters for frequency weightings (A
					and C) required for risk assessments of workers exposed to noise,” Industrial Health, vol. 53, no. 1,
					pp. 21-27, 2015.</li>
				<li>H. Moller and C. Pedersen, “Hearing at low and infrasonic frequencies,” Noise &amp; Health, vol. 6, no.
					23, pp. 37-57, 2004.</li>
				<li>J. O. Smith III, Mathematics of the Discrete Fourier Trans-form (DFT): with Audio Applications Second
					Edition, W3K Publishing, 2007.</li>
				<li>University of Waterloo, “SYDE 252 Linear Systems &amp; Signals,” 2015. [Online]. Available:
					http://www.eng.uwater-loo.ca/~jzelek/teaching/syde252signals/Syde252/syde252-home.html. [Accessed 14 10
					2016].</li>
			</ol>
		</div>
	</div>
    <footer>
        &copy; 2020 Canadian Journal of Undergraduate Research, developed by <a href="https://sutanto.dev">Derrick Sutanto</a><br />
        UBC Undergraduate Research Opportunities, 3500-6133 University Blvd., Vancouver, BC V6T 1Z1
    </footer>

</body>